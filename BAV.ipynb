{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMp1ggnSdH9+E/pghkucEBD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yash-1812/Advance_Python/blob/main/BAV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import zipfile, os\n",
        "\n",
        "# Use uploaded filename automatically\n",
        "zip_path = list(uploaded.keys())[0]\n",
        "print(\"Using ZIP:\", zip_path)\n",
        "\n",
        "output_dir = \"/content/extracted_slides\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "    z.extractall(output_dir)\n",
        "\n",
        "print(\"Extracted to:\", output_dir)\n",
        "\n",
        "# Show extracted files\n",
        "for root, dirs, files_list in os.walk(output_dir):\n",
        "    for f in files_list:\n",
        "        print(os.path.join(root, f))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "ew0Zkecyj10K",
        "outputId": "fbdfc4f2-2fe5-49f2-c997-ddf45c74489d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cb0b4679-bd9a-4067-977c-8e0444dd47ce\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cb0b4679-bd9a-4067-977c-8e0444dd47ce\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Slides-20251114T131049Z-1-001.zip to Slides-20251114T131049Z-1-001.zip\n",
            "Using ZIP: Slides-20251114T131049Z-1-001.zip\n",
            "Extracted to: /content/extracted_slides\n",
            "/content/extracted_slides/Slides/10. Mergers and Acquisitions.pptx\n",
            "/content/extracted_slides/Slides/7. Credit risk analysis.pdf\n",
            "/content/extracted_slides/Slides/8. Relative Valuation.pptx\n",
            "/content/extracted_slides/Slides/11. Mergers and Acquisitions.pptx\n",
            "/content/extracted_slides/Slides/7. Financial Analysis.pptx\n",
            "/content/extracted_slides/Slides/3. Accounting Analysis.pptx\n",
            "/content/extracted_slides/Slides/1. PPT 1.pptx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting Text from pdf and pptx files into txt format"
      ],
      "metadata": {
        "id": "_mW4iBR0kfVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pip install --quiet python-pptx PyPDF2\n",
        "\n",
        "import os, pathlib, json\n",
        "from pptx import Presentation\n",
        "import PyPDF2\n",
        "\n",
        "\n",
        "BASE_DIR = \"/content/extracted_slides/Slides\"\n",
        "OUT_DIR = \"/content/extracted_text\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Reading slides from:\", BASE_DIR)\n",
        "print(\"Saving extracted text to:\", OUT_DIR)\n",
        "\n",
        "manifest = []\n",
        "\n",
        "def extract_text_from_pptx(path):\n",
        "    prs = Presentation(path)\n",
        "    all_text = []\n",
        "\n",
        "    for slide_idx, slide in enumerate(prs.slides, start=1):\n",
        "        slide_text = []\n",
        "        for shape in slide.shapes:\n",
        "            if hasattr(shape, \"text\"): # hasattr -> \"has attribute\" -- here - inspect shape for \"text\"\n",
        "                text = shape.text.strip()\n",
        "                if text:\n",
        "                    slide_text.append(text)\n",
        "        if slide_text:\n",
        "            all_text.append(f\"[[SLIDE {slide_idx}]]\\n\" + \"\\n\".join(slide_text))\n",
        "\n",
        "    return \"\\n\\n\".join(all_text)\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(path):\n",
        "    pages = []\n",
        "    with open(path, \"rb\") as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        for pg, page in enumerate(reader.pages, start=1):\n",
        "            try:\n",
        "                text = page.extract_text()\n",
        "                if text:\n",
        "                    pages.append(f\"[[PAGE {pg}]]\\n{text}\")\n",
        "                else:\n",
        "                    pages.append(f\"[[PAGE {pg}]]\\n[NO TEXT EXTRACTED]\")\n",
        "            except:\n",
        "                pages.append(f\"[[PAGE {pg}]]\\n[ERROR READING PAGE]\")\n",
        "    return \"\\n\\n\".join(pages)\n",
        "\n",
        "\n",
        "for root, dirs, files in os.walk(BASE_DIR):\n",
        "    for file in files:\n",
        "        path = os.path.join(root, file)\n",
        "        ext = pathlib.Path(file).suffix.lower()\n",
        "\n",
        "        if ext not in [\".pptx\", \".pdf\"]:\n",
        "            continue\n",
        "\n",
        "        print(\"Extracting:\", file)\n",
        "\n",
        "        try:\n",
        "            if ext == \".pptx\":\n",
        "                text = extract_text_from_pptx(path)\n",
        "            else:\n",
        "                text = extract_text_from_pdf(path)\n",
        "\n",
        "            # save as .txt\n",
        "            out_path = os.path.join(\n",
        "                OUT_DIR, pathlib.Path(file).stem + \".txt\"\n",
        "            )\n",
        "            with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(text)\n",
        "\n",
        "            manifest.append({\n",
        "                \"source_file\": path,\n",
        "                \"text_file\": out_path,\n",
        "                \"original_size\": os.path.getsize(path)\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"Failed to extract:\", file, \"Error:\", e)\n",
        "\n",
        "manifest_path = os.path.join(OUT_DIR, \"text_manifest.json\")\n",
        "with open(manifest_path, \"w\", encoding=\"utf-8\") as mf:\n",
        "    json.dump(manifest, mf, indent=2)\n",
        "\n",
        "print(\"\\n==== EXTRACTION COMPLETE ====\")\n",
        "print(\"Extracted TXT files are in:\", OUT_DIR)\n",
        "print(\"Manifest saved to:\", manifest_path)\n",
        "\n",
        "for item in manifest:\n",
        "    print(\"✓\", item[\"text_file\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19CHPimQkAd9",
        "outputId": "76047fb0-c09b-4b45-bd6d-1d9c95e962c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/472.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/175.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hReading slides from: /content/extracted_slides/Slides\n",
            "Saving extracted text to: /content/extracted_text\n",
            "Extracting: 10. Mergers and Acquisitions.pptx\n",
            "Extracting: 7. Credit risk analysis.pdf\n",
            "Extracting: 8. Relative Valuation.pptx\n",
            "Extracting: 11. Mergers and Acquisitions.pptx\n",
            "Extracting: 7. Financial Analysis.pptx\n",
            "Extracting: 3. Accounting Analysis.pptx\n",
            "Extracting: 1. PPT 1.pptx\n",
            "\n",
            "==== EXTRACTION COMPLETE ====\n",
            "Extracted TXT files are in: /content/extracted_text\n",
            "Manifest saved to: /content/extracted_text/text_manifest.json\n",
            "✓ /content/extracted_text/10. Mergers and Acquisitions.txt\n",
            "✓ /content/extracted_text/7. Credit risk analysis.txt\n",
            "✓ /content/extracted_text/8. Relative Valuation.txt\n",
            "✓ /content/extracted_text/11. Mergers and Acquisitions.txt\n",
            "✓ /content/extracted_text/7. Financial Analysis.txt\n",
            "✓ /content/extracted_text/3. Accounting Analysis.txt\n",
            "✓ /content/extracted_text/1. PPT 1.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chunking Segment\n",
        "\n",
        "Three functions are created in this segment.\n",
        "\n",
        "--> One for page/slide based chunking\n",
        "\n",
        "--> The other for chunking with overlap, to get relation between segments\n",
        "\n",
        "--> The third for sentence based chuncking"
      ],
      "metadata": {
        "id": "tB5_SnpgmT39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt1gKj8cnHdL",
        "outputId": "736cddf6-d542-4a6b-809d-a44940063b55"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install --quiet nltk\n",
        "\n",
        "import os, json, re, nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from pathlib import Path\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "TEXT_DIR = \"/content/extracted_text\"\n",
        "OUT_DIR = \"/content/rag_chunks\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Reading text from:\", TEXT_DIR)\n",
        "print(\"Saving chunks to:\", OUT_DIR)\n",
        "\n",
        "\n",
        "# Helper: clean text\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.replace(\"\\uf0b7\", \"\")   # bullet artifacts\n",
        "    text = re.sub(r'\\n{3,}', '\\n\\n', text)  # limit excessive newlines\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "# Strategy A: Slide / Page based chunking\n",
        "\n",
        "def chunk_by_markers(text, source_name):\n",
        "    # Markers are like: [[SLIDE 5]] or [[PAGE 3]]\n",
        "    pattern = r\"\\[\\[(SLIDE|PAGE)\\s+\\d+\\]\\]\"\n",
        "    parts = re.split(pattern, text)\n",
        "\n",
        "    chunks = []\n",
        "    slide_num = None\n",
        "    for i in range(0, len(parts)-1, 2):\n",
        "        marker_type = parts[i]\n",
        "        content = parts[i+1].strip()\n",
        "        if not content:\n",
        "            continue\n",
        "\n",
        "        chunks.append({\n",
        "            \"id\": f\"{source_name}_slidepage_{i}\",\n",
        "            \"source\": source_name,\n",
        "            \"slide_or_page\": marker_type,\n",
        "            \"text\": content\n",
        "        })\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# Strategy B: Fixed-size chunks with overlap\n",
        "\n",
        "def chunk_fixed(text, source_name, chunk_size=800, overlap=150):\n",
        "    text = clean_text(text)\n",
        "    chunks = []\n",
        "\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = start + chunk_size\n",
        "        chunk = text[start:end]\n",
        "\n",
        "        chunks.append({\n",
        "            \"id\": f\"{source_name}_fixed_{start}\",\n",
        "            \"source\": source_name,\n",
        "            \"start\": start,\n",
        "            \"end\": end,\n",
        "            \"text\": chunk\n",
        "        })\n",
        "\n",
        "        start = end - overlap\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Sentence based chunking\n",
        "\n",
        "def chunk_sentence_based(text, source_name, max_sentences=5):\n",
        "    text = clean_text(text)\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    chunks = []\n",
        "    for i in range(0, len(sentences), max_sentences):\n",
        "        chunk_sentences = sentences[i:i+max_sentences]\n",
        "        chunk_text = \" \".join(chunk_sentences).strip()\n",
        "\n",
        "        chunks.append({\n",
        "            \"id\": f\"{source_name}_sent_{i}\",\n",
        "            \"source\": source_name,\n",
        "            \"text\": chunk_text\n",
        "        })\n",
        "\n",
        "    return chunks\n",
        "\n",
        "all_chunks = []\n",
        "\n",
        "for file in os.listdir(TEXT_DIR):\n",
        "    if not file.endswith(\".txt\"):\n",
        "        continue\n",
        "\n",
        "    source_path = os.path.join(TEXT_DIR, file)\n",
        "    source_name = Path(file).stem\n",
        "\n",
        "    print(\"Chunking:\", file)\n",
        "\n",
        "    with open(source_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        raw_text = f.read()\n",
        "\n",
        "    raw_text = clean_text(raw_text)\n",
        "\n",
        "    # Using all three stratergies\n",
        "    chunks_A = chunk_by_markers(raw_text, source_name)\n",
        "    chunks_B = chunk_fixed(raw_text, source_name, chunk_size=900, overlap=200)\n",
        "    chunks_C = chunk_sentence_based(raw_text, source_name, max_sentences=4)\n",
        "\n",
        "    all_chunks.extend(chunks_A)\n",
        "    all_chunks.extend(chunks_B)\n",
        "    all_chunks.extend(chunks_C)\n",
        "\n",
        "# Save chunks to JSONL\n",
        "chunks_path = os.path.join(OUT_DIR, \"chunks.jsonl\")\n",
        "with open(chunks_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for ch in all_chunks:\n",
        "        f.write(json.dumps(ch) + \"\\n\")\n",
        "\n",
        "print(\"\\n==== CHUNKING COMPLETE ====\")\n",
        "print(\"Total chunks:\", len(all_chunks))\n",
        "print(\"Saved to:\", chunks_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqsTmaBzlYhW",
        "outputId": "b24defae-845a-4e93-ab6a-2402fbcd19e5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading text from: /content/extracted_text\n",
            "Saving chunks to: /content/rag_chunks\n",
            "Chunking: 8. Relative Valuation.txt\n",
            "Chunking: 7. Financial Analysis.txt\n",
            "Chunking: 10. Mergers and Acquisitions.txt\n",
            "Chunking: 11. Mergers and Acquisitions.txt\n",
            "Chunking: 7. Credit risk analysis.txt\n",
            "Chunking: 3. Accounting Analysis.txt\n",
            "Chunking: 1. PPT 1.txt\n",
            "\n",
            "==== CHUNKING COMPLETE ====\n",
            "Total chunks: 512\n",
            "Saved to: /content/rag_chunks/chunks.jsonl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# The chunks are stored at /content/rag_chunks/chunks.jsonl\n",
        "\n",
        "# Dependencies\n",
        "!pip install --quiet sentence-transformers faiss-cpu transformers accelerate\n",
        "\n",
        "\n",
        "!pip install --quiet \"transformers[torch]\"  # if not already available\n",
        "\n",
        "\n",
        "import os, json, math, time\n",
        "from pathlib import Path\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "CHUNKS_PATH = \"/content/rag_chunks/chunks.jsonl\"\n",
        "EMBED_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"  # Any other model can be used\n",
        "GEN_MODEL_NAME = \"google/flan-t5-base\"                       # For sequence to sequence generation.\n",
        "INDEX_DIR = \"/content/faiss_index\"\n",
        "os.makedirs(INDEX_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "# Can be tweaked. 64 is safe and I have used it before\n",
        "EMBED_BATCH = 64\n",
        "EMBED_DIM = 384\n",
        "TOP_K = 5\n",
        "SEED = 42\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device for generation:\", device)\n",
        "\n",
        "\n",
        "chunks = []\n",
        "with open(CHUNKS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            chunks.append(json.loads(line))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "print(\"Loaded chunks:\", len(chunks))\n",
        "\n",
        "# Create FAISS embeddings\n",
        "index_path = os.path.join(INDEX_DIR, \"faiss.index\")\n",
        "meta_path = os.path.join(INDEX_DIR, \"metadata.jsonl\")\n",
        "\n",
        "if os.path.exists(index_path) and os.path.exists(meta_path):\n",
        "    print(\"Loading existing FAISS index and metadata...\")\n",
        "    index = faiss.read_index(index_path)\n",
        "    metadata = [json.loads(line) for line in open(meta_path, \"r\", encoding=\"utf-8\")]\n",
        "else:\n",
        "    print(\"Creating embeddings and FAISS index from chunks...\")\n",
        "\n",
        "    # load embedding model\n",
        "    embedder = SentenceTransformer(EMBED_MODEL_NAME, device=device)\n",
        "    embedder.max_seq_length = 512\n",
        "\n",
        "    # prepare texts (use chunk text; include small metadata in text if desired)\n",
        "    texts = [ (c.get(\"text\",\"\"), c) for c in chunks ]\n",
        "    all_texts = [t for t,_ in texts]\n",
        "\n",
        "    # batch embed\n",
        "    embeddings = []\n",
        "    for i in tqdm(range(0, len(all_texts), EMBED_BATCH), desc=\"Embedding batches\"):\n",
        "        batch_texts = all_texts[i:i+EMBED_BATCH]\n",
        "        emb = embedder.encode(batch_texts, show_progress_bar=False, convert_to_numpy=True)\n",
        "        embeddings.append(emb)\n",
        "    embeddings = np.vstack(embeddings).astype(\"float32\")\n",
        "    print(\"Embeddings shape:\", embeddings.shape)\n",
        "\n",
        "    # build FAISS index (IndexFlatIP with normalized vectors for cosine)\n",
        "    faiss.normalize_L2(embeddings)  # normalize for cosine-sim using inner product\n",
        "    index = faiss.IndexFlatIP(EMBED_DIM)\n",
        "    index.add(embeddings)\n",
        "    print(\"FAISS index built. n_total =\", index.ntotal)\n",
        "\n",
        "    # save index and metadata\n",
        "    faiss.write_index(index, index_path)\n",
        "    with open(meta_path, \"w\", encoding=\"utf-8\") as mf:\n",
        "        for c in chunks:\n",
        "            mf.write(json.dumps(c, ensure_ascii=False) + \"\\n\")\n",
        "    metadata = chunks.copy()\n",
        "    print(\"Saved index to\", index_path)\n",
        "    print(\"Saved metadata to\", meta_path)\n",
        "\n",
        "# LOAD GENERATOR (seq2seq)\n",
        "print(\"Loading generator model:\", GEN_MODEL_NAME)\n",
        "tokenizer = AutoTokenizer.from_pretrained(GEN_MODEL_NAME)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(GEN_MODEL_NAME).to(device)\n",
        "\n",
        "# small helper: retrieve top-k and return chunks with scores\n",
        "def retrieve(query, top_k=TOP_K):\n",
        "    # embed query with the same embedder used earlier\n",
        "    global embedder\n",
        "    if 'embedder' not in globals():\n",
        "        # lazy load embedder if not present\n",
        "        embedder = SentenceTransformer(EMBED_MODEL_NAME, device=device)\n",
        "        embedder.max_seq_length = 512\n",
        "\n",
        "    q_emb = embedder.encode([query], convert_to_numpy=True)\n",
        "    q_emb = q_emb.astype(\"float32\")\n",
        "    faiss.normalize_L2(q_emb)\n",
        "    D, I = index.search(q_emb, top_k)\n",
        "    results = []\n",
        "    for score, idx in zip(D[0], I[0]):\n",
        "        md = metadata[idx]\n",
        "        results.append({\n",
        "            \"score\": float(score),\n",
        "            \"chunk_id\": md.get(\"id\"),\n",
        "            \"source\": md.get(\"source\"),\n",
        "            \"text\": md.get(\"text\", \"\")[:3000]  # cap preview length\n",
        "        })\n",
        "    return results\n",
        "\n",
        "#  (Optional) Rerank using cross-encoder (heavy)\n",
        "# from sentence_transformers import CrossEncoder\n",
        "# reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', device=device)\n",
        "# def rerank(query, candidates):\n",
        "#     pairs = [[query, c['text']] for c in candidates]\n",
        "#     scores = reranker.predict(pairs)\n",
        "#     for c,s in zip(candidates, scores):\n",
        "#         c['rerank_score'] = float(s)\n",
        "#     candidates = sorted(candidates, key=lambda x: x['rerank_score'], reverse=True)\n",
        "#     return candidates\n",
        "\n",
        "# Assemble prompt and generate answer\n",
        "def generate_answer(query, top_k=TOP_K, max_length=256):\n",
        "    # retrieve\n",
        "    results = retrieve(query, top_k=top_k)\n",
        "    # optional rerank:\n",
        "    # results = rerank(query, results)\n",
        "\n",
        "    # build context string from the retrieved chunks\n",
        "    context_blocks = []\n",
        "    for i, r in enumerate(results, start=1):\n",
        "        block = f\"[SOURCE {i}] {r['source']}\\n{r['text']}\"\n",
        "        context_blocks.append(block)\n",
        "\n",
        "    context = \"\\n\\n\".join(context_blocks)\n",
        "\n",
        "    # build prompt for the seq2seq generator\n",
        "    # For Flan-T5 style, a short instruction works well.\n",
        "    prompt = (\n",
        "        \"You are an assistant answering questions using the provided context. \"\n",
        "        \"Use only the facts in the context to answer and cite the sources in brackets. \"\n",
        "        \"If the answer isn't in the context, say 'I don't know'.\\n\\n\"\n",
        "        f\"CONTEXT:\\n{context}\\n\\nQUESTION: {query}\\n\\nAnswer:\"\n",
        "    )\n",
        "\n",
        "    # tokenize and generate\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_length,\n",
        "            num_beams=4,\n",
        "            early_stopping=True,\n",
        "            no_repeat_ngram_size=3\n",
        "        )\n",
        "    ans = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return {\"answer\": ans, \"retrieved\": results, \"prompt\": prompt}\n",
        "\n",
        "# Simple interactive query loop (or use programmatically)\n",
        "print(\"\\nRAG system ready. Try calling generate_answer(query).\\n\")\n",
        "print(\"Example:\")\n",
        "example_q = \"What is relative valuation and when is it useful?\"\n",
        "res = generate_answer(example_q, top_k=4)\n",
        "print(\"ANSWER:\\n\", res['answer'])\n",
        "print(\"\\nRETRIEVED SOURCES:\")\n",
        "for r in res['retrieved']:\n",
        "    print(\" -\", r['source'], \"| score:\", round(r['score'], 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2FUbSr-oifa",
        "outputId": "a194aa11-6199-422f-ad4d-4388bf99be64"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device for generation: cuda\n",
            "Loaded chunks: 512\n",
            "Loading existing FAISS index and metadata...\n",
            "Loading generator model: google/flan-t5-base\n",
            "\n",
            "RAG system ready. Try calling generate_answer(query).\n",
            "\n",
            "Example:\n",
            "ANSWER:\n",
            " In relative valuation, an asset is valued on the basis of how similar assets are currently priced in the market\n",
            "\n",
            "RETRIEVED SOURCES:\n",
            " - 8. Relative Valuation | score: 0.825\n",
            " - 8. Relative Valuation | score: 0.754\n",
            " - 1. PPT 1 | score: 0.637\n",
            " - 1. PPT 1 | score: 0.631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O7taTO4HqtiB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}