{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import files\\n\"\n",
        "import zipfile\\n\"\n",
        "import os\\n\"\n",
        "\\n\"\n",
        "# Create directories\\n\"\n",
        "os.makedirs(\\\"data/previous_papers\\\", exist_ok=True)\\n\"\n",
        "os.makedirs(\\\"data/extracted_texts\\\", exist_ok=True)\\n\"\n",
        "\\n\"\n",
        "print(\\\" Upload your ZIP containing PDF papers\\\")\\n\"\n",
        "uploaded = files.upload()\\n\"\n",
        "\\n\"\n",
        "# Extract ZIP\\n\"\n",
        "for filename in uploaded.keys():\\n\"\n",
        "    if filename.endswith(\\\".zip\\\"):\\n\"\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\\n\"\n",
        "            zip_ref.extractall(\\\"data/previous_papers\\\")\\n\"\n",
        "        print(f\\\"Extracted {filename} to data/previous_papers/\\\")\\n\n"
      ],
      "outputs": [],
      "execution_count": 0
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "! pip install -q pytesseract pdf2image pillow tqdm\n"
      ],
      "outputs": null,
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import files\\n\"\n",
        "uploaded = files.upload()\n"
      ],
      "outputs": [],
      "execution_count": 0
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\\n\"\n",
        "\\n\"\n",
        "zip_path = list(uploaded.keys())[0\n"
      ],
      "outputs": [],
      "execution_count": 0
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!apt-get install -y poppler-utils\n"
      ],
      "outputs": null,
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# STEP 1 \u2014 Install dependencies\\n\"\n",
        "!apt-get install -y poppler-utils\\n\"\n",
        "!pip install pytesseract pdf2image Pillow tqdm\\n\"\n",
        "\\n\"\n",
        "# STEP 2 \u2014 Imports\\n\"\n",
        "import os\\n\"\n",
        "import pytesseract\\n\"\n",
        "from pdf2image import convert_from_path\\n\"\n",
        "from PIL import Image\\n\"\n",
        "from tqdm import tqdm\\n\"\n",
        "\\n\"\n",
        "# STEP 3 \u2014 Paths\\n\"\n",
        "pdf_folder = \\\"data/previous_papers/DRM_Questions\\\"\\n\"\n",
        "output_folder = \\\"data/extracted_texts\\\"\\n\"\n",
        "os.makedirs(output_folder, exist_ok=True)\\n\"\n",
        "\\n\"\n",
        "combined_text_path = os.path.join(output_folder, \\\"all_papers.txt\\\")\\n\"\n",
        "\\n\"\n",
        "# STEP 4 \u2014 OCR Extraction\\n\"\n",
        "all_text = \\\"\\\"\\n\"\n",
        "pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith(\\\".pdf\\\")\n"
      ],
      "outputs": [],
      "execution_count": 0
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "combined_text_path = \\\"data/extracted_texts/all_papers.txt\\\"\\n\"\n",
        "\\n\"\n",
        "with open(combined_text_path, \\\"r\\\", encoding=\\\"utf-8\\\") as f:\\n\"\n",
        "    text = f.read()\\n\"\n",
        "\\n\"\n",
        "print(f\\\"Total characters in OCR text: {len(text)}\\\")\\n\"\n",
        "print(\\\"\\\\nPreview (first 1000 characters):\\\\n\\\")\\n\"\n",
        "print(text[:1000\n"
      ],
      "outputs": [],
      "execution_count": 0
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import re\\n\"\n",
        "\\n\"\n",
        "def extract_questions(text):\\n\"\n",
        "    # Normalize spaces and line breaks\\n\"\n",
        "    text = re.sub(r'\\\\s+', ' ', text)\\n\"\n",
        "\\n\"\n",
        "    # Split text using question patterns\\n\"\n",
        "    raw_questions = re.split(r'(?:(?:Q\\\\d+)|(?:\\\\d+\\\\.\\\\s)|(?:\\\\?))', text)\\n\"\n",
        "\\n\"\n",
        "    # Clean and filter\\n\"\n",
        "    questions = [q.strip() for q in raw_questions if len(q.strip()) > 15\n"
      ],
      "outputs": [],
      "execution_count": 0
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install sentence-transformers faiss-cpu\\n\"\n",
        "\\n\"\n",
        "from sentence_transformers import SentenceTransformer\\n\"\n",
        "import faiss\\n\"\n",
        "import numpy as np\\n\"\n",
        "\\n\"\n",
        "embedder = SentenceTransformer(\\\"all-MiniLM-L6-v2\\\")\\n\"\n",
        "\\n\"\n",
        "# Create embeddings for all questions\\n\"\n",
        "question_embeddings = embedder.encode(questions, convert_to_numpy=True)\\n\"\n",
        "\\n\"\n",
        "# Build FAISS index\\n\"\n",
        "index = faiss.IndexFlatL2(question_embeddings.shape[1\n"
      ],
      "outputs": [],
      "execution_count": 0
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def search_questions(query, top_k=5):\\n\"\n",
        "    query_vec = embedder.encode([query\n"
      ],
      "outputs": [],
      "execution_count": 0
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}